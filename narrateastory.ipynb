{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73573c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9353a694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\backup\\narrateastory\n"
     ]
    }
   ],
   "source": [
    "# !pip install owlrl\n",
    "import os\n",
    "\n",
    "# Specify the desired directory\n",
    "directory_path = r\"C:\\backup\\narrateastory\"\n",
    "\n",
    "# Change the current working directory\n",
    "os.chdir(directory_path)\n",
    "\n",
    "# Verify the change\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current working directory:\", current_directory)\n",
    "\n",
    "\n",
    "from rdflib import Graph, Namespace, RDF, RDFS, OWL, Literal\n",
    "from rdflib.plugins import stores\n",
    "import csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8c815d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9057ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set swrl in protege\n",
    "hasAncientTradeRoutes(?a, ?b) ^ hasAncientTradeRoutes(?b, ?c) -> hasAncientTradeRoutes(?a, ?c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4078ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db5b439e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred: http://narrateastory.com/heritageontology#nathula http://narrateastory.com/heritageontology#hasAncientTradeRoute http://narrateastory.com/heritageontology#Tamralipta\n",
      "Inferred: http://narrateastory.com/heritageontology#nathula http://narrateastory.com/heritageontology#hasAncientTradeRoute http://narrateastory.com/heritageontology#Saptagram\n",
      "Inferred: http://narrateastory.com/heritageontology#chandraketugarh http://narrateastory.com/heritageontology#hasAncientTradeRoute http://narrateastory.com/heritageontology#Rome\n",
      "Inferred: http://narrateastory.com/heritageontology#nathula http://narrateastory.com/heritageontology#hasAncientTradeRoute http://narrateastory.com/heritageontology#Rome\n"
     ]
    }
   ],
   "source": [
    "# Ontology Development\n",
    "\n",
    "import csv\n",
    "from rdflib import Graph, Literal, Namespace, RDF, RDFS, OWL, URIRef\n",
    "\n",
    "# Create the RDF graph and define the namespaces\n",
    "rdf_graph = Graph()\n",
    "ex = Namespace(\"http://narrateastory.com/heritageontology#\")\n",
    "\n",
    "rdf_graph.bind(\"ex\", ex)\n",
    "rdf_graph.bind(\"owl\", OWL)\n",
    "rdf_graph.bind(\"rdfs\", RDFS)\n",
    "\n",
    "# Define inferred_triples at a higher scope\n",
    "inferred_triples = set()\n",
    "\n",
    "# Function to infer transitive closure\n",
    "def infer_transitive_closure(graph, property_uri, visited_triples=None):\n",
    "    if visited_triples is None:\n",
    "        visited_triples = set()\n",
    "\n",
    "    global inferred_triples  # Reference the global variable\n",
    "    for s1, p, o1 in graph.triples((None, property_uri, None)):\n",
    "        for s2, _, o2 in graph.triples((None, property_uri, s1)):\n",
    "            inferred_triple = (s2, property_uri, o1)\n",
    "            if inferred_triple not in visited_triples:\n",
    "                graph.add(inferred_triple)\n",
    "                inferred_triples.add(inferred_triple)\n",
    "                print(f\"Inferred: {inferred_triple[0]} {inferred_triple[1]} {inferred_triple[2]}\")\n",
    "                visited_triples.add(inferred_triple)\n",
    "                # Recursively check for more transitive closure\n",
    "                infer_transitive_closure(graph, property_uri, visited_triples)\n",
    "\n",
    "# Read the CSV file and build the ontology\n",
    "with open(\"markers_data.csv\", \"r\", encoding=\"utf-8-sig\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "\n",
    "    for row in reader:\n",
    "        subject = row[\"subject\"].replace(\" \", \"_\")\n",
    "        relation = row[\"relation\"]\n",
    "        obj = row[\"obj\"].replace(\" \", \"_\")\n",
    "\n",
    "        subject_uri = ex[subject]\n",
    "        obj_uri = ex[obj]\n",
    "\n",
    "        # Check if the relation is \"isa\" to determine superclass-subclass relationship\n",
    "        if relation.lower() == \"isa\":\n",
    "            # Check if the subclass relation already exists to avoid conflicts\n",
    "            if (subject_uri, RDFS.subClassOf, obj_uri) not in rdf_graph and (obj_uri, RDFS.subClassOf, subject_uri) not in rdf_graph:\n",
    "                rdf_graph.add((subject_uri, RDF.type, OWL.Class))\n",
    "                rdf_graph.add((obj_uri, RDF.type, OWL.Class))\n",
    "                rdf_graph.add((obj_uri, RDFS.subClassOf, subject_uri))\n",
    "                inferred_triples.add((subject_uri, RDFS.subClassOf, obj_uri))\n",
    "            else:\n",
    "                print(f\"Conflict detected: {subject} {relation} {obj}. Skipping.\")\n",
    "\n",
    "        else:\n",
    "            # Check if the reverse relation exists to avoid conflicts\n",
    "            if (obj_uri, ex[relation], subject_uri) not in rdf_graph:\n",
    "                # Add subject and obj classes\n",
    "                rdf_graph.add((subject_uri, RDF.type, OWL.Class))\n",
    "                rdf_graph.add((obj_uri, RDF.type, OWL.Class))\n",
    "\n",
    "                # Add relation property\n",
    "                relation_uri = ex[relation]\n",
    "                rdf_graph.add((relation_uri, RDF.type, OWL.ObjectProperty))\n",
    "\n",
    "                # Add individual instances\n",
    "                rdf_graph.add((subject_uri, RDF.type, subject_uri))\n",
    "                rdf_graph.add((obj_uri, RDF.type, obj_uri))\n",
    "\n",
    "                # Add relation between subject and obj classes\n",
    "                rdf_graph.add((subject_uri, relation_uri, obj_uri))\n",
    "\n",
    "                # Add relation between subject and obj instances\n",
    "                rdf_graph.add((subject_uri, relation_uri, obj_uri))\n",
    "                inferred_triples.add((subject_uri, relation_uri, obj_uri))\n",
    "\n",
    "                # Add additional properties as RDFS:seeAlso\n",
    "                if \"timePeriod\" in row:\n",
    "                    rdf_graph.add((subject_uri, RDFS.seeAlso, Literal(row[\"timePeriod\"])))\n",
    "                if \"lat\" in row and \"long\" in row:\n",
    "                    rdf_graph.add((subject_uri, RDFS.seeAlso, Literal(f\"Lat: {row['lat']}, Long: {row['long']}\")))\n",
    "                if \"utube_link\" in row:\n",
    "                    rdf_graph.add((subject_uri, RDFS.seeAlso, URIRef(row[\"utube_link\"])))\n",
    "                if \"further_reading\" in row:\n",
    "                    rdf_graph.add((subject_uri, RDFS.seeAlso, URIRef(row[\"further_reading\"])))\n",
    "                if \"current_name_of_place\" in row:\n",
    "                    rdf_graph.add((subject_uri, RDFS.seeAlso, Literal(row[\"current_name_of_place\"])))\n",
    "\n",
    "            else:\n",
    "                print(f\"Conflict detected: {subject} {relation} {obj}. Skipping.\")\n",
    "\n",
    "# Infer transitive closure for \"hasAncientTradeRoute\" (not \"hasAncientTradeRoutes\")\n",
    "infer_transitive_closure(rdf_graph, ex.hasAncientTradeRoute)\n",
    "\n",
    "# Save the entire inferred graph to an RDF file\n",
    "rdf_graph.serialize(destination=\"inferredtriples.owl\", format=\"xml\")\n",
    "\n",
    "# Save the inferred triples to a CSV file with \"|\" delimiter\n",
    "with open(\"inferredtriples.csv\", \"a\", encoding=\"utf-8-sig\", newline=\"\") as csvfile:\n",
    "    csv_writer = csv.writer(csvfile, delimiter=\"|\")\n",
    "    for inferred_triple in inferred_triples:\n",
    "        if not inferred_triple[0].endswith(\"_instance\") and not inferred_triple[2].endswith(\"_instance\"):\n",
    "            csv_writer.writerow([inferred_triple[0].split(\"#\")[1], inferred_triple[1].split(\"#\")[1], inferred_triple[2].split(\"#\")[1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384b9ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14095b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance Matrix:\n",
      "                 tamralipta  saptagram  nathula  chandraketugarh  rome\n",
      "tamralipta              0.0        inf      1.0              1.0   1.0\n",
      "saptagram               inf        0.0      1.0              1.0   inf\n",
      "nathula                 1.0        1.0      0.0              1.0   1.0\n",
      "chandraketugarh         1.0        1.0      1.0              0.0   1.0\n",
      "rome                    1.0        inf      1.0              1.0   0.0\n",
      "\n",
      "Distance Matrix for hasTravelObstacle:\n",
      "                 chandraketugarh  airport  saptagram\n",
      "chandraketugarh              0.0      inf        inf\n",
      "airport                      inf      0.0        inf\n",
      "saptagram                    inf      inf        0.0\n",
      "\n",
      "Modified Distance Matrix:\n",
      "                 tamralipta  saptagram  nathula  chandraketugarh  rome\n",
      "tamralipta              0.0        inf      1.0              0.5   1.0\n",
      "saptagram               inf        0.0      0.5              0.5   inf\n",
      "nathula                 1.0        0.5      0.0              0.5   1.0\n",
      "chandraketugarh         0.5        0.5      0.5              0.0   0.5\n",
      "rome                    1.0        inf      1.0              0.5   0.0\n",
      "\n",
      "Shortest Distance from chandraketugarh to saptagram: 0.5\n",
      "Shortest Path: chandraketugarh -> saptagram\n",
      "\n",
      "CSV Data:\n",
      "Location1,Location2,Distance\n",
      "tamralipta,tamralipta,0.0\n",
      "tamralipta,saptagram,inf\n",
      "tamralipta,nathula,1.0\n",
      "tamralipta,chandraketugarh,0.5\n",
      "tamralipta,rome,1.0\n",
      "saptagram,tamralipta,inf\n",
      "saptagram,saptagram,0.0\n",
      "saptagram,nathula,0.5\n",
      "saptagram,chandraketugarh,0.5\n",
      "saptagram,rome,inf\n",
      "nathula,tamralipta,1.0\n",
      "nathula,saptagram,0.5\n",
      "nathula,nathula,0.0\n",
      "nathula,chandraketugarh,0.5\n",
      "nathula,rome,1.0\n",
      "chandraketugarh,tamralipta,0.5\n",
      "chandraketugarh,saptagram,0.5\n",
      "chandraketugarh,nathula,0.5\n",
      "chandraketugarh,chandraketugarh,0.0\n",
      "chandraketugarh,rome,0.5\n",
      "rome,tamralipta,1.0\n",
      "rome,saptagram,inf\n",
      "rome,nathula,1.0\n",
      "rome,chandraketugarh,0.5\n",
      "rome,rome,0.0\n",
      "\n",
      "CSV file 'distance_matrix_csv_format.csv' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# SUBJECTIVE DISTANCE BETWEEN PLACES\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import heapq\n",
    "\n",
    "# Function to parse the OWL file and extract triples with a specific object property\n",
    "def parse_owl_file(file_path, target_object_property):\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Extract namespaces\n",
    "    namespaces = {\n",
    "        'rdf': 'http://www.w3.org/1999/02/22-rdf-syntax-ns#',\n",
    "        'ex': 'http://narrateastory.com/heritageontology#'\n",
    "    }\n",
    "\n",
    "    triples = []\n",
    "\n",
    "    # Loop through RDF descriptions in the XML file\n",
    "    for description in root.findall(\".//rdf:Description\", namespaces=namespaces):\n",
    "        about = description.get(\"{\" + namespaces['rdf'] + \"}about\").split(\"#\")[-1].lower()\n",
    "\n",
    "        # Find object properties matching the target property\n",
    "        for prop in description.findall(f\".//ex:{target_object_property}\", namespaces=namespaces):\n",
    "            related_resource = prop.get(\"{\" + namespaces['rdf'] + \"}resource\").split(\"#\")[-1].lower()\n",
    "            triples.append((about, target_object_property, related_resource))\n",
    "\n",
    "    return triples\n",
    "\n",
    "# Function to create a distance matrix from triples\n",
    "def create_distance_matrix(triples):\n",
    "    locations = list(set([triple[0] for triple in triples] + [triple[2] for triple in triples]))\n",
    "    num_locations = len(locations)\n",
    "    distance_matrix = np.inf * np.ones((num_locations, num_locations))\n",
    "\n",
    "    location_index = {location: index for index, location in enumerate(locations)}\n",
    "\n",
    "    # Assigning a distance of 1 if the relationship is hasAncientTradeRoute\n",
    "    for start, relationship, end in triples:\n",
    "        start_index = location_index[start]\n",
    "        end_index = location_index[end]\n",
    "        if relationship == 'hasAncientTradeRoute':\n",
    "            distance_matrix[start_index, end_index] = 1\n",
    "            distance_matrix[end_index, start_index] = 1  # assuming symmetric distance\n",
    "\n",
    "    np.fill_diagonal(distance_matrix, 0)  # Diagonal elements should be zero\n",
    "\n",
    "    return distance_matrix, locations\n",
    "\n",
    "# Function for Dijkstra's algorithm to find the shortest path\n",
    "def dijkstra(graph, start, end, locations):\n",
    "    heap = [(0, start, [])]\n",
    "    visited = set()\n",
    "\n",
    "    while heap:\n",
    "        (cost, current, path) = heapq.heappop(heap)\n",
    "\n",
    "        if current in visited:\n",
    "            continue\n",
    "\n",
    "        visited.add(current)\n",
    "        path = path + [locations[current]]\n",
    "\n",
    "        if current == end:\n",
    "            return cost, path\n",
    "\n",
    "        for next_loc, next_cost in enumerate(graph[current]):\n",
    "            if next_cost != np.inf and next_loc not in visited:\n",
    "                heapq.heappush(heap, (cost + next_cost, next_loc, path))\n",
    "\n",
    "    return np.inf, []\n",
    "\n",
    "# Load and process the OWL file for hasAncientTradeRoute\n",
    "owl_file_path = \"inferredtriples.owl\"\n",
    "target_object_property = \"hasAncientTradeRoute\"\n",
    "triples = parse_owl_file(owl_file_path, target_object_property)\n",
    "\n",
    "# Create distance matrix for hasAncientTradeRoute\n",
    "distance_matrix, all_locations = create_distance_matrix(triples)\n",
    "\n",
    "# Save distance matrix to a csv file \n",
    "header = \" \".join(all_locations)\n",
    "df = pd.DataFrame(distance_matrix, columns=all_locations, index=all_locations)\n",
    "#df.to_csv('distance_matrix.csv', sep=',', float_format='%.2f')\n",
    "\n",
    "# Display the distance matrix for hasAncientTradeRoute\n",
    "print(\"\\nDistance Matrix:\")\n",
    "print(df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load and process the OWL file for hasTravelObstacle\n",
    "target_object_property = \"hasTravelObstacle\"\n",
    "triples = parse_owl_file(owl_file_path, target_object_property)\n",
    "\n",
    "# Create distance matrix for hasTravelObstacle\n",
    "distance_matrix_hasTravelObstacle, all_locations_hasTravelObstacle = create_distance_matrix(triples)\n",
    "\n",
    "# Display the distance matrix for hasTravelObstacle\n",
    "print(\"\\nDistance Matrix for hasTravelObstacle:\")\n",
    "print(pd.DataFrame(distance_matrix_hasTravelObstacle, columns=all_locations_hasTravelObstacle, index=all_locations_hasTravelObstacle))\n",
    "\n",
    "# Extract subjects and objects dynamically\n",
    "subjects_objects = set()\n",
    "for subject, _, obj in triples:\n",
    "    subjects_objects.add(subject)\n",
    "    subjects_objects.add(obj)\n",
    "\n",
    "# Subtract 0.5 from rows and columns with headers that have the relation \"hasTravelObstacle\"\n",
    "headers_to_subtract = list(subjects_objects)\n",
    "\n",
    "adjusted_cells = set()\n",
    "\n",
    "for header in headers_to_subtract:\n",
    "    if header in all_locations:\n",
    "        index = all_locations.index(header)\n",
    "        for i in range(len(distance_matrix)):\n",
    "            if (index, i) not in adjusted_cells:\n",
    "                distance_matrix[i, index] -= 0.5\n",
    "                distance_matrix[index, i] -= 0.5\n",
    "                if distance_matrix[i, index] < 0:\n",
    "                    distance_matrix[i, index] = 0\n",
    "                if distance_matrix[index, i] < 0:\n",
    "                    distance_matrix[index, i] = 0\n",
    "                adjusted_cells.add((index, i))\n",
    "                adjusted_cells.add((i, index))\n",
    "\n",
    "# Display the modified distance matrix\n",
    "print(\"\\nModified Distance Matrix:\")\n",
    "print(pd.DataFrame(distance_matrix, columns=all_locations, index=all_locations))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example: Find the Dijkstra shortest distance and path between two places\n",
    "start_place = \"chandraketugarh\"\n",
    "end_place = \"saptagram\"\n",
    "\n",
    "start_index = all_locations.index(start_place)\n",
    "end_index = all_locations.index(end_place)\n",
    "\n",
    "shortest_distance, shortest_path = dijkstra(df.values, start_index, end_index, all_locations)\n",
    "\n",
    "print(f\"\\nShortest Distance from {start_place} to {end_place}: {shortest_distance}\")\n",
    "print(f\"Shortest Path: {' -> '.join(shortest_path)}\")\n",
    "\n",
    "\n",
    "# Create a list to store the CSV data\n",
    "csv_data = []\n",
    "\n",
    "# Add header row\n",
    "csv_data.append(','.join([\"Location1\", \"Location2\", \"Distance\"]))\n",
    "\n",
    "# Iterate over the distance matrix and create CSV data\n",
    "for i in range(len(df)):\n",
    "    for j in range(len(df.columns)):\n",
    "        location1 = df.index[i]\n",
    "        location2 = df.columns[j]\n",
    "        distance = df.iloc[i, j]\n",
    "        combined_places = f\"{location1},{location2}\"\n",
    "        csv_data.append(','.join([combined_places, str(distance)]))\n",
    "\n",
    "# Save the CSV data to a file\n",
    "with open('distance_matrix_csv_format.csv', 'w') as csv_file:\n",
    "    csv_file.write('\\n'.join(csv_data))\n",
    "\n",
    "# Display the created CSV data\n",
    "print(\"\\nCSV Data:\")\n",
    "for line in csv_data:\n",
    "    print(line)\n",
    "\n",
    "# Display message indicating successful CSV creation\n",
    "print(\"\\nCSV file 'distance_matrix_csv_format.csv' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a8a454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9e9dae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
